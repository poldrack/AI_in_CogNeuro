{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for encoding/decoding models\n",
    "\n",
    "For this example, we will use the data from Haxby et al., 2001., which are shared via OpenNeuro:\n",
    "\n",
    "https://openneuro.org/datasets/ds000105/versions/3.0.0\n",
    "\n",
    "The data are formatted according to the BIDS standard: https://bids-specification.readthedocs.io/en/stable/index.html\n",
    "\n",
    "First, import required dependencies. You can install these using `pip install -r requirements.txt` from the main repo directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import nilearn\n",
    "from nilearn import datasets, plotting\n",
    "from nilearn.image import load_img, mean_img, resample_img\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.plotting import plot_stat_map, plot_design_matrix\n",
    "from nilearn.maskers import MultiNiftiMapsMasker\n",
    "import h5py\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import datalad.api as dl\n",
    "from bids import BIDSLayout\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from templateflow import api as tflow\n",
    "import templateflow\n",
    "import tqdm\n",
    "from utils import (get_difumo_mask, \n",
    "                   get_subject_common_brain_mask,\n",
    "                   get_group_common_mask,\n",
    "                   get_subject_runs,\n",
    "                   get_layouts,\n",
    "                   get_combined_subject_difumo_mask)\n",
    "from poldracklab.utils.run_shell_cmd import run_shell_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data using datalad\n",
    "\n",
    "We will use a tool called [Datalad](https://www.datalad.org/) to obtain the data from openneuro. \n",
    "\n",
    "We will download the raw data, as well as the processed data (using [fMRIPrep](https://fmriprep.org/en/stable/).  Note that downloading these derivative data can take quite a while depending on the speed of one's connection.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Ensuring presence of Dataset(/Users/poldrack/data_unsynced/ds000105) to get /Users/poldrack/data_unsynced/ds000105 \n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/Users/poldrack/data_unsynced/ds000105\"\n",
    "assert os.path.exists(data_dir), \"Data directory not found: %s\" % data_dir\n",
    "fmriprep_dir = os.path.join(data_dir, 'derivatives', 'fmriprep')\n",
    "\n",
    "output_dir = os.path.join(data_dir, 'derivatives', 'cleaned')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "# get the raw data\n",
    "ds = dl.clone(\n",
    "    path=data_dir,\n",
    "    source=\"https://github.com/OpenNeuroDatasets/ds000105.git\",\n",
    ")\n",
    "dl.get(dataset=data_dir, recursive=True)\n",
    "\n",
    "get_fmriprep = False  #set to false after downloading fmriprep once\n",
    "\n",
    "# get the preprocessed derivatives - this takes some time!\n",
    "if get_fmriprep:\n",
    "    dl.clone(\n",
    "        path=fmriprep_dir,\n",
    "        source='https://github.com/OpenNeuroDerivatives/ds000105-fmriprep.git')\n",
    "    dl.get(dataset=fmriprep_dir, recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to grab the data from nilearn, which contains the visual cortical masks used in the original study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_dataset_dir] Dataset found in /Users/poldrack/nilearn_data/haxby2001\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "# First, we fetch single subject specific data with haxby datasets: to have\n",
    "# anatomical image, EPI images and masks images\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "haxby_datadir = os.path.dirname(haxby_dataset.mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the dataset using PyBIDS\n",
    "\n",
    "Because the dataset is organized using the BIDS standard, we can use the [PyBIDS](https://bids-standard.github.io/pybids/) tool to query the dataset and obtain useful metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poldrack/micromamba/envs/aineuro/lib/python3.12/site-packages/bids/layout/layout.py:516: UserWarning: Derivative indexing was requested, but no valid datasets were found in the specified locations ([PosixPath('/Users/poldrack/data_unsynced/ds000105/derivatives/fmriprep/derivatives')]). Note that all BIDS-Derivatives datasets must meet all the requirements for BIDS-Raw datasets (a common problem is to fail to include a 'dataset_description.json' file in derivatives datasets).\n",
      "Example contents of 'dataset_description.json':\n",
      "{\"Name\": \"Example dataset\", \"BIDSVersion\": \"1.0.2\", \"GeneratedBy\": [{\"Name\": \"Example pipeline\"}]}\n",
      "  warnings.warn(\"Derivative indexing was requested, but no valid \"\n"
     ]
    }
   ],
   "source": [
    "# load the dataset using pybids and get runs for each subject\n",
    "\n",
    "\n",
    "layout, deriv_layout = get_layouts(data_dir, fmriprep_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create 3mm resolution version of the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 71 bold files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 71/71 [00:00<00:00, 46126.95it/s]\n"
     ]
    }
   ],
   "source": [
    "boldfiles = deriv_layout.get(desc='preproc', space='MNI152NLin2009cAsym',\n",
    "                            suffix='bold', extension='nii.gz', res=2,\n",
    "                            return_type='file')\n",
    "print(f'found {len(boldfiles)} bold files')\n",
    "\n",
    "target_affine = np.diag((3, 3, 3))\n",
    "\n",
    "for boldfile in tqdm.tqdm(boldfiles, desc=\"Processing items\"):\n",
    "    output = boldfile.replace('res-2', 'res-3')\n",
    "    assert output != boldfile\n",
    "    if not os.path.exists(output):\n",
    "        img = nilearn.image.resample_img(boldfile, target_affine=target_affine, \n",
    "                                        copy_header=True, force_resample=True)\n",
    "        img.to_filename(output)\n",
    "    # create boldref as well\n",
    "    boldref = boldfile.replace('desc-preproc_bold.nii.gz', 'boldref.nii.gz')\n",
    "    output_boldref = boldref.replace('res-2', 'res-3')\n",
    "    assert output_boldref != boldref\n",
    "    if not os.path.exists(output_boldref):\n",
    "        img = nilearn.image.resample_img(boldref, target_affine=target_affine, \n",
    "                                        copy_header=True, force_resample=True)\n",
    "        img.to_filename(output_boldref)\n",
    "    # create mask\n",
    "    maskfile = boldfile.replace('desc-preproc_bold.nii.gz', 'desc-brain_mask.nii.gz')\n",
    "    output_maskfile = maskfile.replace('res-2', 'res-3')\n",
    "    assert output_maskfile != maskfile\n",
    "    if not os.path.exists(maskfile):\n",
    "        img = nilearn.image.resample_img(maskfile, target_affine=target_affine, \n",
    "                                        interpolation='nearest',\n",
    "                                        copy_header=True, force_resample=True)\n",
    "        img.to_filename(output_maskfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/poldrack/data_unsynced/ds000105/derivatives/fmriprep/sub-6/func/sub-6_task-objectviewing_run-12_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boldfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create common mask for each subject\n",
    "\n",
    "Each run will have slightly different voxels included in its brain mask, but we want to have a common mask across all runs, so we will generate a mask that includes the intersection of masks across all of the individual subs/runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mask = get_group_common_mask(layout, res=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confound regression\n",
    "\n",
    "Use the outputs from fMRIPrep to generate a denoised version of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 has 12 runs\n",
      "Subject 2 has 12 runs\n",
      "Subject 3 has 12 runs\n",
      "Subject 4 has 12 runs\n",
      "Subject 5 has 11 runs\n",
      "Subject 6 has 12 runs\n"
     ]
    }
   ],
   "source": [
    "def run_confound_regression(layout, deriv_layout, data_dir, \n",
    "                            res=3, overwrite=False):\n",
    "    cleaned_images = {}\n",
    "\n",
    "    subjects = [int(sub) for sub in layout.get_subjects()]\n",
    "    for subject in subjects:\n",
    "        cleaned_images[subject] = {}\n",
    "        runs = get_subject_runs(subject, data_dir)\n",
    "        print(f'Subject {subject} has {len(runs)} runs')\n",
    "        mask_img = get_subject_common_brain_mask(subject, data_dir, res=res)\n",
    "        #mask_img = resample_img(mask_img, target_affine=np.diag((3, 3, 3)), \n",
    "        #                        interpolation='nearest',\n",
    "        #                        copy_header=True, force_resample=True)\n",
    "        t_r = None\n",
    "        for run in runs:\n",
    "            preproc_file = deriv_layout.get(subject=subject, run=run, res=res,\n",
    "                                            desc='preproc', space='MNI152NLin2009cAsym',\n",
    "                                            suffix='bold', extension='nii.gz', \n",
    "                                            return_type='file')\n",
    "            cleaned_img_file = preproc_file[0].replace('preproc','cleaned')\n",
    "            if t_r is None:\n",
    "                t_r = deriv_layout.get_metadata(preproc_file[0])['RepetitionTime']\n",
    "            else:\n",
    "                assert t_r == deriv_layout.get_metadata(preproc_file[0])['RepetitionTime']\n",
    "            assert t_r is not None\n",
    "            if os.path.exists(cleaned_img_file) and not overwrite:\n",
    "                #print(f\"Using existing cleaned file for subject {subject} run {run}\")\n",
    "                cleaned_img = nib.load(cleaned_img_file)\n",
    "                cleaned_images[subject][run] =  (cleaned_img_file, cleaned_img)\n",
    "                continue\n",
    "            preproc_img = nib.load(preproc_file[0])\n",
    "            assert len(preproc_file) == 1, f\"Found {len(preproc_file)} preproc files for subject {subject} run {run}\"\n",
    "            confound_file = deriv_layout.get(subject=subject, run=run, \n",
    "                                            desc='confounds', \n",
    "                                            suffix='timeseries', extension='tsv', \n",
    "                                            return_type='file')\n",
    "            assert len(confound_file) == 1, f\"Found {len(confound_file)} confound files for subject {subject} run {run}\"\n",
    "            confounds = pd.read_csv(confound_file[0], sep='\\t').bfill()\n",
    "            # need to include cosine with acompcor\n",
    "            confound_prefixes = ['trans_', 'rot_', 'a_comp_cor_', 'cosine']\n",
    "            confound_cols = [c for c in list(confounds.columns) if any([c.startswith(p) for p in confound_prefixes])]\n",
    "            confounds_selected = confounds[confound_cols]\n",
    "            cleaned_img = nilearn.image.clean_img(preproc_img,\n",
    "                                    confounds=confounds_selected,\n",
    "                                    t_r=t_r,mask_img=mask_img)\n",
    "            assert cleaned_img_file != preproc_file[0]\n",
    "            cleaned_img.to_filename(os.path.join(cleaned_img_file))\n",
    "            cleaned_images[subject][run] = (cleaned_img_file, cleaned_img)\n",
    "    return cleaned_images, t_r\n",
    "\n",
    "# refresh the layouts to detect the new res-3 files\n",
    "layout, deriv_layout = get_layouts(data_dir, fmriprep_dir)\n",
    "\n",
    "cleaned_images, t_r = run_confound_regression(\n",
    "    layout, deriv_layout, data_dir, overwrite=True, res=3)\n",
    "\n",
    "cleaned_images, t_r = run_confound_regression(\n",
    "    layout, deriv_layout, data_dir, overwrite=True, res=2)                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select task block timepoints\n",
    "\n",
    "drop the first two TRs from each task block, and generate task labels for each timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the condition label for timepoints that are beyond the intial 4 seconds\n",
    "def get_cond_info(layout, deriv_layout, t_r, cleaned_images,\n",
    "                  blocklen=20, n_trials_to_skip=2):\n",
    "    cond_info = {}\n",
    "\n",
    "    subjects = [int(sub) for sub in layout.get_subjects()]\n",
    "    for subject in subjects:\n",
    "        runs = get_subject_runs(subject, data_dir)\n",
    "        cond_info[subject] = {}\n",
    "        for run in runs:\n",
    "            events_file = layout.get(subject=subject, run=run, datatype='func', extension='tsv', \n",
    "                                    return_type='file')[0]\n",
    "            events = pd.read_csv(events_file, sep='\\t')\n",
    "            n_timepoints = cleaned_images[subject][run][1].shape[-1]\n",
    "            timepoints = np.arange(0, n_timepoints * t_r, t_r)\n",
    "\n",
    "            # find task onsets in the events file\n",
    "             # skip 2 trials i.e. 4 seconds\n",
    "            blocklen = 20 # block length in seconds after removing first 4 seconds\n",
    "\n",
    "            conditions = events.trial_type.unique().tolist()\n",
    "            conditions.sort()\n",
    "            onsets = {}\n",
    "            for condition in conditions:\n",
    "                match_df = events[events.trial_type == condition]\n",
    "                onsets[condition] = match_df.onset.tolist()[n_trials_to_skip]     \n",
    "            cond_df = pd.DataFrame({'timepoint': timepoints, 'condition': None})\n",
    "            for idx in cond_df.index:\n",
    "                for condition in conditions:\n",
    "                    if cond_df.loc[idx, 'timepoint'] >= onsets[condition] and cond_df.loc[idx, 'timepoint'] < (onsets[condition] + blocklen):\n",
    "                        cond_df.loc[idx, 'condition'] = condition\n",
    "            for cond in cond_df.condition.unique():\n",
    "                if cond is None:\n",
    "                    continue\n",
    "                assert len(cond_df[cond_df.condition == cond]) == 8\n",
    "            cond_info[subject][run] = cond_df\n",
    "    return cond_info\n",
    "        \n",
    "cond_info = get_cond_info(layout, deriv_layout, t_r, cleaned_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_task_images(cond_info, cleaned_images):\n",
    "    task_images = {}\n",
    "    task_info = {}\n",
    "    for subject, runs in cond_info.items():\n",
    "        task_images[subject] = {}\n",
    "        task_info[subject] = {}\n",
    "        for run, cond_df in runs.items():\n",
    "            good_trials = cond_df.dropna()\n",
    "            assert len(good_trials) == 64, f\"Found {len(good_trials)} good trials for subject {subject} run {run}\"\n",
    "            task_img_file = cleaned_images[subject][run][0].replace('cleaned', 'task')\n",
    "            assert task_img_file != cleaned_images[subject][run][0]\n",
    "            good_trials.to_csv(task_img_file.replace('_bold.nii.gz', '_events.tsv'), sep='\\t', index=False)\n",
    "            task_info[subject][run] = good_trials\n",
    "            if not os.path.exists(task_img_file):\n",
    "                cleaned_img = cleaned_images[subject][run][1]\n",
    "                task_data = cleaned_img.get_fdata()[:, :, :, list(good_trials.index)]\n",
    "                task_img = nib.Nifti1Image(task_data, cleaned_img.affine)\n",
    "                task_img.to_filename(task_img_file)\n",
    "            else:\n",
    "                task_img = nib.load(task_img_file)\n",
    "            task_images[subject][run] = task_img\n",
    "    return task_images, task_info\n",
    "\n",
    "task_images, task_info = get_task_images(cond_info, cleaned_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save to HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_dataset_dir] Dataset found in /Users/poldrack/nilearn_data/difumo_atlases\n",
      "Processing subject 1\n",
      "Processing subject 2\n",
      "Processing subject 3\n",
      "Processing subject 4\n",
      "Processing subject 5\n",
      "Processing subject 6\n"
     ]
    }
   ],
   "source": [
    "subjects = [int(sub) for sub in layout.get_subjects()]\n",
    "\n",
    "\n",
    "difumo = datasets.fetch_atlas_difumo(\n",
    "    dimension=1024, resolution_mm=3, legacy_format=False\n",
    ")\n",
    "difumo_masker = MultiNiftiMapsMasker(\n",
    "    maps_img=difumo.maps,\n",
    "    n_jobs=12,\n",
    ")\n",
    "\n",
    "vtmaskdir = os.path.join(data_dir, 'derivatives', 'vtmasks')\n",
    "with h5py.File(os.path.join(output_dir, 'haxby_data_cleaned.h5'), 'w') as hf:\n",
    "\n",
    "    for subject in subjects:\n",
    "        print(f'Processing subject {subject}')\n",
    "        g1 = hf.create_group(f'sub-{subject}')\n",
    "\n",
    "        runs = get_subject_runs(subject, data_dir)\n",
    "        sub_mask = get_subject_common_brain_mask(subject, data_dir)\n",
    "        masker = NiftiMasker(mask_img=sub_mask)\n",
    "        vt_mask = nib.load(os.path.join(vtmaskdir, \n",
    "                                        f'sub-{subject}_mask4vt_space-MNI152NLin2009cAsym_res-3.nii.gz'))\n",
    "\n",
    "        vtmasker = NiftiMasker(mask_img=vt_mask)\n",
    "        for run in runs:\n",
    "            g2 = g1.create_group(f'run-{run}')\n",
    "\n",
    "            vt_data = vtmasker.fit_transform(task_images[subject][run])\n",
    "            assert vt_data.shape[0] == task_images[subject][run].shape[-1]\n",
    "            assert vt_data.shape[1] == np.sum(vt_mask.get_fdata())\n",
    "            g2.create_dataset(f'vtmaskdata',data=vt_data)\n",
    "\n",
    "            # get the whole brain data\n",
    "            braindata = masker.fit_transform(task_images[subject][run])\n",
    "            assert braindata.shape[0] == task_images[subject][run].shape[-1]\n",
    "            assert braindata.shape[1] == np.sum(sub_mask.get_fdata())\n",
    "            g2.create_dataset(f'braindata',data=braindata)\n",
    "\n",
    "            g2.create_dataset(f'conditions', data=[c.encode('utf-8') for c in task_info[subject][run].condition.tolist()])\n",
    "\n",
    "            # get the difumo data\n",
    "            difumo_data = difumo_masker.fit_transform(task_images[subject][run])\n",
    "            assert difumo_data.shape[0] == task_images[subject][run].shape[-1]\n",
    "            g2.create_dataset(f'difumodata',data=difumo_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average within blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(output_dir, 'haxby_data_cleaned.h5'), 'a') as hf:\n",
    "\n",
    "    subjects = [int(sub) for sub in layout.get_subjects()]\n",
    "    for subject in subjects:\n",
    "        runs = get_subject_runs(subject, data_dir)\n",
    "        for run in runs:\n",
    "            conditions = [i.decode('utf-8') for i in hf[f'sub-{subject}/run-{run}']['conditions'][:]]\n",
    "\n",
    "            vt_df = pd.DataFrame(hf[f'sub-{subject}/run-{run}']['vtmaskdata'][:])\n",
    "            condition_mean_df = vt_df.groupby(conditions).mean().sort_index()\n",
    "            conditions_collapsed = condition_mean_df.index.values\n",
    "            hf[f'sub-{subject}/run-{run}'].create_dataset('mean_vtmaskdata', data=condition_mean_df)\n",
    "            hf[f'sub-{subject}/run-{run}'].create_dataset('mean_conditions', data=condition_mean_df.index.values)\n",
    "\n",
    "            # same for whole brain\n",
    "            brain_df = pd.DataFrame(hf[f'sub-{subject}/run-{run}']['braindata'][:])\n",
    "            condition_mean_df = brain_df.groupby(conditions).mean().sort_index()\n",
    "            # make sure conditions are the same between the two\n",
    "            assert np.all(condition_mean_df.index.values == conditions_collapsed)\n",
    "            hf[f'sub-{subject}/run-{run}'].create_dataset('mean_braindata', data=condition_mean_df)\n",
    "\n",
    "            # same for difumo\n",
    "            difumo_df = pd.DataFrame(hf[f'sub-{subject}/run-{run}']['difumodata'][:])\n",
    "            condition_mean_df = difumo_df.groupby(conditions).mean().sort_index()\n",
    "            # make sure conditions are the same between the two\n",
    "            assert np.all(condition_mean_df.index.values == conditions_collapsed)\n",
    "            hf[f'sub-{subject}/run-{run}'].create_dataset('mean_difumodata', data=condition_mean_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>736</th>\n",
       "      <th>737</th>\n",
       "      <th>738</th>\n",
       "      <th>739</th>\n",
       "      <th>740</th>\n",
       "      <th>741</th>\n",
       "      <th>742</th>\n",
       "      <th>743</th>\n",
       "      <th>744</th>\n",
       "      <th>745</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bottle</th>\n",
       "      <td>0.223510</td>\n",
       "      <td>0.555354</td>\n",
       "      <td>0.076189</td>\n",
       "      <td>0.806277</td>\n",
       "      <td>0.434506</td>\n",
       "      <td>-0.127566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755435</td>\n",
       "      <td>0.658588</td>\n",
       "      <td>0.283284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.046888</td>\n",
       "      <td>0.649071</td>\n",
       "      <td>1.105127</td>\n",
       "      <td>0.212456</td>\n",
       "      <td>0.425591</td>\n",
       "      <td>0.787501</td>\n",
       "      <td>0.166978</td>\n",
       "      <td>-0.118653</td>\n",
       "      <td>0.015284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.077047</td>\n",
       "      <td>0.137659</td>\n",
       "      <td>0.610137</td>\n",
       "      <td>0.651860</td>\n",
       "      <td>0.886337</td>\n",
       "      <td>1.290706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.974121</td>\n",
       "      <td>-0.866428</td>\n",
       "      <td>0.093341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.142750</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>0.122959</td>\n",
       "      <td>-0.572202</td>\n",
       "      <td>-0.600489</td>\n",
       "      <td>-0.650052</td>\n",
       "      <td>-0.209627</td>\n",
       "      <td>-0.013346</td>\n",
       "      <td>-0.586770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chair</th>\n",
       "      <td>-0.549344</td>\n",
       "      <td>0.202728</td>\n",
       "      <td>-0.343461</td>\n",
       "      <td>-0.404575</td>\n",
       "      <td>-0.219456</td>\n",
       "      <td>-0.390653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.496782</td>\n",
       "      <td>0.033021</td>\n",
       "      <td>-0.360628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.358664</td>\n",
       "      <td>-0.108972</td>\n",
       "      <td>-0.188834</td>\n",
       "      <td>0.233812</td>\n",
       "      <td>0.022475</td>\n",
       "      <td>-0.418732</td>\n",
       "      <td>0.255603</td>\n",
       "      <td>0.344937</td>\n",
       "      <td>0.032109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face</th>\n",
       "      <td>1.102448</td>\n",
       "      <td>-0.168833</td>\n",
       "      <td>0.316184</td>\n",
       "      <td>0.089225</td>\n",
       "      <td>0.085655</td>\n",
       "      <td>0.257923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.899937</td>\n",
       "      <td>0.816107</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695500</td>\n",
       "      <td>0.337529</td>\n",
       "      <td>0.152436</td>\n",
       "      <td>0.152873</td>\n",
       "      <td>0.093059</td>\n",
       "      <td>0.187460</td>\n",
       "      <td>0.131131</td>\n",
       "      <td>-0.242762</td>\n",
       "      <td>-0.011046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>-0.036800</td>\n",
       "      <td>0.581824</td>\n",
       "      <td>0.295780</td>\n",
       "      <td>0.910669</td>\n",
       "      <td>0.217340</td>\n",
       "      <td>0.088864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659120</td>\n",
       "      <td>0.687724</td>\n",
       "      <td>0.101085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749987</td>\n",
       "      <td>-0.442448</td>\n",
       "      <td>0.456267</td>\n",
       "      <td>0.877891</td>\n",
       "      <td>0.681471</td>\n",
       "      <td>0.969104</td>\n",
       "      <td>0.227239</td>\n",
       "      <td>0.504431</td>\n",
       "      <td>0.822614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scissors</th>\n",
       "      <td>0.905370</td>\n",
       "      <td>-0.131680</td>\n",
       "      <td>-0.039496</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.448615</td>\n",
       "      <td>0.129861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116251</td>\n",
       "      <td>0.305961</td>\n",
       "      <td>0.752645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146558</td>\n",
       "      <td>0.744469</td>\n",
       "      <td>0.509111</td>\n",
       "      <td>0.019412</td>\n",
       "      <td>-0.205082</td>\n",
       "      <td>-0.313374</td>\n",
       "      <td>-0.304020</td>\n",
       "      <td>0.251243</td>\n",
       "      <td>0.203370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrambledpix</th>\n",
       "      <td>0.574243</td>\n",
       "      <td>-0.621280</td>\n",
       "      <td>0.283549</td>\n",
       "      <td>-0.590334</td>\n",
       "      <td>-0.400695</td>\n",
       "      <td>0.371679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003813</td>\n",
       "      <td>-0.472249</td>\n",
       "      <td>0.220851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.205344</td>\n",
       "      <td>0.150616</td>\n",
       "      <td>-0.202023</td>\n",
       "      <td>-0.832213</td>\n",
       "      <td>-0.614411</td>\n",
       "      <td>-0.468885</td>\n",
       "      <td>0.375162</td>\n",
       "      <td>-0.431919</td>\n",
       "      <td>-0.646878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shoe</th>\n",
       "      <td>0.350214</td>\n",
       "      <td>0.322173</td>\n",
       "      <td>0.101463</td>\n",
       "      <td>-0.325659</td>\n",
       "      <td>0.316855</td>\n",
       "      <td>0.047294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126292</td>\n",
       "      <td>0.019877</td>\n",
       "      <td>0.135888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.271094</td>\n",
       "      <td>0.767303</td>\n",
       "      <td>-0.036735</td>\n",
       "      <td>-0.429698</td>\n",
       "      <td>-0.619716</td>\n",
       "      <td>-0.684324</td>\n",
       "      <td>0.260812</td>\n",
       "      <td>-0.086315</td>\n",
       "      <td>0.297907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 746 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5    6    \\\n",
       "bottle        0.223510  0.555354  0.076189  0.806277  0.434506 -0.127566  0.0   \n",
       "cat           0.077047  0.137659  0.610137  0.651860  0.886337  1.290706  0.0   \n",
       "chair        -0.549344  0.202728 -0.343461 -0.404575 -0.219456 -0.390653  0.0   \n",
       "face          1.102448 -0.168833  0.316184  0.089225  0.085655  0.257923  0.0   \n",
       "house        -0.036800  0.581824  0.295780  0.910669  0.217340  0.088864  0.0   \n",
       "scissors      0.905370 -0.131680 -0.039496  0.010098  0.448615  0.129861  0.0   \n",
       "scrambledpix  0.574243 -0.621280  0.283549 -0.590334 -0.400695  0.371679  0.0   \n",
       "shoe          0.350214  0.322173  0.101463 -0.325659  0.316855  0.047294  0.0   \n",
       "\n",
       "                   7         8         9    ...  736       737       738  \\\n",
       "bottle        0.755435  0.658588  0.283284  ...  0.0  1.046888  0.649071   \n",
       "cat          -0.974121 -0.866428  0.093341  ...  0.0 -0.142750  0.024354   \n",
       "chair        -0.496782  0.033021 -0.360628  ...  0.0 -0.358664 -0.108972   \n",
       "face          0.899937  0.816107  0.994276  ...  0.0  0.695500  0.337529   \n",
       "house         0.659120  0.687724  0.101085  ...  0.0  0.749987 -0.442448   \n",
       "scissors      0.116251  0.305961  0.752645  ...  0.0  0.146558  0.744469   \n",
       "scrambledpix -0.003813 -0.472249  0.220851  ...  0.0 -0.205344  0.150616   \n",
       "shoe         -0.126292  0.019877  0.135888  ...  0.0 -0.271094  0.767303   \n",
       "\n",
       "                   739       740       741       742       743       744  \\\n",
       "bottle        1.105127  0.212456  0.425591  0.787501  0.166978 -0.118653   \n",
       "cat           0.122959 -0.572202 -0.600489 -0.650052 -0.209627 -0.013346   \n",
       "chair        -0.188834  0.233812  0.022475 -0.418732  0.255603  0.344937   \n",
       "face          0.152436  0.152873  0.093059  0.187460  0.131131 -0.242762   \n",
       "house         0.456267  0.877891  0.681471  0.969104  0.227239  0.504431   \n",
       "scissors      0.509111  0.019412 -0.205082 -0.313374 -0.304020  0.251243   \n",
       "scrambledpix -0.202023 -0.832213 -0.614411 -0.468885  0.375162 -0.431919   \n",
       "shoe         -0.036735 -0.429698 -0.619716 -0.684324  0.260812 -0.086315   \n",
       "\n",
       "                   745  \n",
       "bottle        0.015284  \n",
       "cat          -0.586770  \n",
       "chair         0.032109  \n",
       "face         -0.011046  \n",
       "house         0.822614  \n",
       "scissors      0.203370  \n",
       "scrambledpix -0.646878  \n",
       "shoe          0.297907  \n",
       "\n",
       "[8 rows x 746 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_mean_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 71991)\n",
      "(64, 746)\n",
      "(64, 1024)\n",
      "(64,)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "with h5py.File(os.path.join(output_dir, 'haxby_data_cleaned.h5'), 'r') as hf:\n",
    "\n",
    "    #utils.list_all_datasets(hf)\n",
    "    print(hf[f'sub-{subject}/run-{run}']['braindata'].shape)\n",
    "    print(hf[f'sub-{subject}/run-{run}']['vtmaskdata'].shape)\n",
    "    print(hf[f'sub-{subject}/run-{run}']['difumodata'].shape)\n",
    "\n",
    "    print(hf[f'sub-{subject}/run-{run}']['conditions'].shape)\n",
    "    print(hf[f'sub-{subject}/run-{run}']['mean_conditions'].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
