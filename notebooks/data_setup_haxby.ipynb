{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8dfa354",
   "metadata": {},
   "source": [
    "## Data preparation for encoding/decoding models\n",
    "\n",
    "For this example, we will use the data from Haxby et al., 2001., which are shared via OpenNeuro:\n",
    "\n",
    "https://openneuro.org/datasets/ds000105/versions/3.0.0\n",
    "\n",
    "The data are formatted according to the BIDS standard: https://bids-specification.readthedocs.io/en/stable/index.html\n",
    "\n",
    "First, import required dependencies. You can install these using `pip install -r requirements.txt` from the main repo directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import nilearn\n",
    "from nilearn import datasets\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.maskers import MultiNiftiMapsMasker\n",
    "import h5py\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import datalad.api as dl\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from utils import (\n",
    "    get_subject_common_brain_mask,\n",
    "    get_group_common_mask,\n",
    "    get_subject_runs,\n",
    "    get_layouts,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef9986",
   "metadata": {},
   "source": [
    "#### Get the data using datalad\n",
    "\n",
    "We will use a tool called [Datalad](https://www.datalad.org/) to obtain the data from openneuro.\n",
    "\n",
    "We will download the raw data, as well as the processed data (using [fMRIPrep](https://fmriprep.org/en/stable/).  Note that downloading these derivative data can take quite a while depending on the speed of one's connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/poldrack/data_unsynced/ds000105'\n",
    "assert os.path.exists(data_dir), 'Data directory not found: %s' % data_dir\n",
    "fmriprep_dir = os.path.join(data_dir, 'derivatives', 'fmriprep')\n",
    "\n",
    "output_dir = os.path.join(data_dir, 'derivatives', 'cleaned')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "# get the raw data\n",
    "ds = dl.clone(\n",
    "    path=data_dir,\n",
    "    source='https://github.com/OpenNeuroDatasets/ds000105.git',\n",
    ")\n",
    "dl.get(dataset=data_dir, recursive=True)\n",
    "\n",
    "get_fmriprep = False  # set to false after downloading fmriprep once\n",
    "\n",
    "# get the preprocessed derivatives - this takes some time!\n",
    "if get_fmriprep:\n",
    "    dl.clone(\n",
    "        path=fmriprep_dir,\n",
    "        source='https://github.com/OpenNeuroDerivatives/ds000105-fmriprep.git',\n",
    "    )\n",
    "    dl.get(dataset=fmriprep_dir, recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb4068",
   "metadata": {},
   "source": [
    "We also need to grab the data from nilearn, which contains the visual cortical masks used in the original study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3eee88",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# First, we fetch single subject specific data with haxby datasets: to have\n",
    "# anatomical image, EPI images and masks images\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "haxby_datadir = os.path.dirname(haxby_dataset.mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5748c0",
   "metadata": {},
   "source": [
    "### Query the dataset using PyBIDS\n",
    "\n",
    "Because the dataset is organized using the BIDS standard, we can use the [PyBIDS](https://bids-standard.github.io/pybids/) tool to query the dataset and obtain useful metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad1ecee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# load the dataset using pybids and get runs for each subject\n",
    "\n",
    "\n",
    "layout, deriv_layout = get_layouts(data_dir, fmriprep_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e176f",
   "metadata": {},
   "source": [
    "### create 3mm resolution version of the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19de266",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "boldfiles = deriv_layout.get(\n",
    "    desc='preproc',\n",
    "    space='MNI152NLin2009cAsym',\n",
    "    suffix='bold',\n",
    "    extension='nii.gz',\n",
    "    res=2,\n",
    "    return_type='file',\n",
    ")\n",
    "print(f'found {len(boldfiles)} bold files')\n",
    "\n",
    "target_affine = np.diag((3, 3, 3))\n",
    "\n",
    "for boldfile in tqdm.tqdm(boldfiles, desc='Processing items'):\n",
    "    output = boldfile.replace('res-2', 'res-3')\n",
    "    assert output != boldfile\n",
    "    if not os.path.exists(output):\n",
    "        img = nilearn.image.resample_img(\n",
    "            boldfile,\n",
    "            target_affine=target_affine,\n",
    "            copy_header=True,\n",
    "            force_resample=True,\n",
    "        )\n",
    "        img.to_filename(output)\n",
    "    # create boldref as well\n",
    "    boldref = boldfile.replace('desc-preproc_bold.nii.gz', 'boldref.nii.gz')\n",
    "    output_boldref = boldref.replace('res-2', 'res-3')\n",
    "    assert output_boldref != boldref\n",
    "    if not os.path.exists(output_boldref):\n",
    "        img = nilearn.image.resample_img(\n",
    "            boldref,\n",
    "            target_affine=target_affine,\n",
    "            copy_header=True,\n",
    "            force_resample=True,\n",
    "        )\n",
    "        img.to_filename(output_boldref)\n",
    "    # create mask\n",
    "    maskfile = boldfile.replace(\n",
    "        'desc-preproc_bold.nii.gz', 'desc-brain_mask.nii.gz'\n",
    "    )\n",
    "    output_maskfile = maskfile.replace('res-2', 'res-3')\n",
    "    assert output_maskfile != maskfile\n",
    "    if not os.path.exists(maskfile):\n",
    "        img = nilearn.image.resample_img(\n",
    "            maskfile,\n",
    "            target_affine=target_affine,\n",
    "            interpolation='nearest',\n",
    "            copy_header=True,\n",
    "            force_resample=True,\n",
    "        )\n",
    "        img.to_filename(output_maskfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b22407",
   "metadata": {},
   "outputs": [],
   "source": [
    "boldfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b0fef",
   "metadata": {},
   "source": [
    "### Create common mask for each subject\n",
    "\n",
    "Each run will have slightly different voxels included in its brain mask, but we want to have a common mask across all runs, so we will generate a mask that includes the intersection of masks across all of the individual subs/runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c47bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mask = get_group_common_mask(layout, res=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b055d4f",
   "metadata": {},
   "source": [
    "### Confound regression\n",
    "\n",
    "Use the outputs from fMRIPrep to generate a denoised version of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9be120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_confound_regression(\n",
    "    layout, deriv_layout, data_dir, res=3, overwrite=False\n",
    "):\n",
    "    cleaned_images = {}\n",
    "\n",
    "    subjects = [int(sub) for sub in layout.get_subjects()]\n",
    "    for subject in subjects:\n",
    "        cleaned_images[subject] = {}\n",
    "        runs = get_subject_runs(subject, data_dir)\n",
    "        print(f'Subject {subject} has {len(runs)} runs')\n",
    "        mask_img = get_subject_common_brain_mask(subject, data_dir, res=res)\n",
    "        # mask_img = resample_img(mask_img, target_affine=np.diag((3, 3, 3)),\n",
    "        #                        interpolation='nearest',\n",
    "        #                        copy_header=True, force_resample=True)\n",
    "        t_r = None\n",
    "        for run in runs:\n",
    "            preproc_file = deriv_layout.get(\n",
    "                subject=subject,\n",
    "                run=run,\n",
    "                res=res,\n",
    "                desc='preproc',\n",
    "                space='MNI152NLin2009cAsym',\n",
    "                suffix='bold',\n",
    "                extension='nii.gz',\n",
    "                return_type='file',\n",
    "            )\n",
    "            cleaned_img_file = preproc_file[0].replace('preproc', 'cleaned')\n",
    "            if t_r is None:\n",
    "                t_r = deriv_layout.get_metadata(preproc_file[0])[\n",
    "                    'RepetitionTime'\n",
    "                ]\n",
    "            else:\n",
    "                assert (\n",
    "                    t_r\n",
    "                    == deriv_layout.get_metadata(preproc_file[0])[\n",
    "                        'RepetitionTime'\n",
    "                    ]\n",
    "                )\n",
    "            assert t_r is not None\n",
    "            if os.path.exists(cleaned_img_file) and not overwrite:\n",
    "                # print(f\"Using existing cleaned file for subject {subject} run {run}\")\n",
    "                cleaned_img = nib.load(cleaned_img_file)\n",
    "                cleaned_images[subject][run] = (cleaned_img_file, cleaned_img)\n",
    "                continue\n",
    "            preproc_img = nib.load(preproc_file[0])\n",
    "            assert (\n",
    "                len(preproc_file) == 1\n",
    "            ), f'Found {len(preproc_file)} preproc files for subject {subject} run {run}'\n",
    "            confound_file = deriv_layout.get(\n",
    "                subject=subject,\n",
    "                run=run,\n",
    "                desc='confounds',\n",
    "                suffix='timeseries',\n",
    "                extension='tsv',\n",
    "                return_type='file',\n",
    "            )\n",
    "            assert (\n",
    "                len(confound_file) == 1\n",
    "            ), f'Found {len(confound_file)} confound files for subject {subject} run {run}'\n",
    "            confounds = pd.read_csv(confound_file[0], sep='\\t').bfill()\n",
    "            # need to include cosine with acompcor\n",
    "            confound_prefixes = ['trans_', 'rot_', 'a_comp_cor_', 'cosine']\n",
    "            confound_cols = [\n",
    "                c\n",
    "                for c in list(confounds.columns)\n",
    "                if any([c.startswith(p) for p in confound_prefixes])\n",
    "            ]\n",
    "            confounds_selected = confounds[confound_cols]\n",
    "            cleaned_img = nilearn.image.clean_img(\n",
    "                preproc_img,\n",
    "                confounds=confounds_selected,\n",
    "                t_r=t_r,\n",
    "                mask_img=mask_img,\n",
    "            )\n",
    "            assert cleaned_img_file != preproc_file[0]\n",
    "            cleaned_img.to_filename(os.path.join(cleaned_img_file))\n",
    "            cleaned_images[subject][run] = (cleaned_img_file, cleaned_img)\n",
    "    return cleaned_images, t_r\n",
    "\n",
    "\n",
    "# refresh the layouts to detect the new res-3 files\n",
    "layout, deriv_layout = get_layouts(data_dir, fmriprep_dir)\n",
    "\n",
    "cleaned_images, t_r = run_confound_regression(\n",
    "    layout, deriv_layout, data_dir, overwrite=True, res=3\n",
    ")\n",
    "\n",
    "cleaned_images, t_r = run_confound_regression(\n",
    "    layout, deriv_layout, data_dir, overwrite=True, res=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7cab62",
   "metadata": {},
   "source": [
    "### select task block timepoints\n",
    "\n",
    "drop the first two TRs from each task block, and generate task labels for each timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6707a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# find the condition label for timepoints that are beyond the intial 4 seconds\n",
    "def get_cond_info(\n",
    "    layout, deriv_layout, t_r, cleaned_images, blocklen=20, n_trials_to_skip=2\n",
    "):\n",
    "    cond_info = {}\n",
    "\n",
    "    subjects = [int(sub) for sub in layout.get_subjects()]\n",
    "    for subject in subjects:\n",
    "        runs = get_subject_runs(subject, data_dir)\n",
    "        cond_info[subject] = {}\n",
    "        for run in runs:\n",
    "            events_file = layout.get(\n",
    "                subject=subject,\n",
    "                run=run,\n",
    "                datatype='func',\n",
    "                extension='tsv',\n",
    "                return_type='file',\n",
    "            )[0]\n",
    "            events = pd.read_csv(events_file, sep='\\t')\n",
    "            n_timepoints = cleaned_images[subject][run][1].shape[-1]\n",
    "            timepoints = np.arange(0, n_timepoints * t_r, t_r)\n",
    "\n",
    "            # find task onsets in the events file\n",
    "            # skip 2 trials i.e. 4 seconds\n",
    "            blocklen = (\n",
    "                20  # block length in seconds after removing first 4 seconds\n",
    "            )\n",
    "\n",
    "            conditions = events.trial_type.unique().tolist()\n",
    "            conditions.sort()\n",
    "            onsets = {}\n",
    "            for condition in conditions:\n",
    "                match_df = events[events.trial_type == condition]\n",
    "                onsets[condition] = match_df.onset.tolist()[n_trials_to_skip]\n",
    "            cond_df = pd.DataFrame(\n",
    "                {'timepoint': timepoints, 'condition': None}\n",
    "            )\n",
    "            for idx in cond_df.index:\n",
    "                for condition in conditions:\n",
    "                    if cond_df.loc[idx, 'timepoint'] >= onsets[\n",
    "                        condition\n",
    "                    ] and cond_df.loc[idx, 'timepoint'] < (\n",
    "                        onsets[condition] + blocklen\n",
    "                    ):\n",
    "                        cond_df.loc[idx, 'condition'] = condition\n",
    "            for cond in cond_df.condition.unique():\n",
    "                if cond is None:\n",
    "                    continue\n",
    "                assert len(cond_df[cond_df.condition == cond]) == 8\n",
    "            cond_info[subject][run] = cond_df\n",
    "    return cond_info\n",
    "\n",
    "\n",
    "cond_info = get_cond_info(layout, deriv_layout, t_r, cleaned_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9813a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_task_images(cond_info, cleaned_images):\n",
    "    task_images = {}\n",
    "    task_info = {}\n",
    "    for subject, runs in cond_info.items():\n",
    "        task_images[subject] = {}\n",
    "        task_info[subject] = {}\n",
    "        for run, cond_df in runs.items():\n",
    "            good_trials = cond_df.dropna()\n",
    "            assert (\n",
    "                len(good_trials) == 64\n",
    "            ), f'Found {len(good_trials)} good trials for subject {subject} run {run}'\n",
    "            task_img_file = cleaned_images[subject][run][0].replace(\n",
    "                'cleaned', 'task'\n",
    "            )\n",
    "            assert task_img_file != cleaned_images[subject][run][0]\n",
    "            good_trials.to_csv(\n",
    "                task_img_file.replace('_bold.nii.gz', '_events.tsv'),\n",
    "                sep='\\t',\n",
    "                index=False,\n",
    "            )\n",
    "            task_info[subject][run] = good_trials\n",
    "            if not os.path.exists(task_img_file):\n",
    "                cleaned_img = cleaned_images[subject][run][1]\n",
    "                task_data = cleaned_img.get_fdata()[\n",
    "                    :, :, :, list(good_trials.index)\n",
    "                ]\n",
    "                task_img = nib.Nifti1Image(task_data, cleaned_img.affine)\n",
    "                task_img.to_filename(task_img_file)\n",
    "            else:\n",
    "                task_img = nib.load(task_img_file)\n",
    "            task_images[subject][run] = task_img\n",
    "    return task_images, task_info\n",
    "\n",
    "\n",
    "task_images, task_info = get_task_images(cond_info, cleaned_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30340562",
   "metadata": {},
   "source": [
    "### save to HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0725fb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "subjects = [int(sub) for sub in layout.get_subjects()]\n",
    "\n",
    "\n",
    "difumo = datasets.fetch_atlas_difumo(\n",
    "    dimension=1024, resolution_mm=3, legacy_format=False\n",
    ")\n",
    "difumo_masker = MultiNiftiMapsMasker(\n",
    "    maps_img=difumo.maps,\n",
    "    n_jobs=12,\n",
    ")\n",
    "\n",
    "vtmaskdir = os.path.join(data_dir, 'derivatives', 'vtmasks')\n",
    "with h5py.File(os.path.join(output_dir, 'haxby_data_cleaned.h5'), 'w') as hf:\n",
    "\n",
    "    for subject in subjects:\n",
    "        print(f'Processing subject {subject}')\n",
    "        g1 = hf.create_group(f'sub-{subject}')\n",
    "\n",
    "        runs = get_subject_runs(subject, data_dir)\n",
    "        sub_mask = get_subject_common_brain_mask(subject, data_dir)\n",
    "        masker = NiftiMasker(mask_img=sub_mask)\n",
    "        vt_mask = nib.load(\n",
    "            os.path.join(\n",
    "                vtmaskdir,\n",
    "                f'sub-{subject}_mask4vt_space-MNI152NLin2009cAsym_res-3.nii.gz',\n",
    "            )\n",
    "        )\n",
    "\n",
    "        vtmasker = NiftiMasker(mask_img=vt_mask)\n",
    "        for run in runs:\n",
    "            g2 = g1.create_group(f'run-{run}')\n",
    "\n",
    "            vt_data = vtmasker.fit_transform(task_images[subject][run])\n",
    "            assert vt_data.shape[0] == task_images[subject][run].shape[-1]\n",
    "            assert vt_data.shape[1] == np.sum(vt_mask.get_fdata())\n",
    "            g2.create_dataset('vtmaskdata', data=vt_data)\n",
    "\n",
    "            # get the whole brain data\n",
    "            braindata = masker.fit_transform(task_images[subject][run])\n",
    "            assert braindata.shape[0] == task_images[subject][run].shape[-1]\n",
    "            assert braindata.shape[1] == np.sum(sub_mask.get_fdata())\n",
    "            g2.create_dataset('braindata', data=braindata)\n",
    "\n",
    "            g2.create_dataset(\n",
    "                'conditions',\n",
    "                data=[\n",
    "                    c.encode('utf-8')\n",
    "                    for c in task_info[subject][run].condition.tolist()\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # get the difumo data\n",
    "            difumo_data = difumo_masker.fit_transform(\n",
    "                task_images[subject][run]\n",
    "            )\n",
    "            assert difumo_data.shape[0] == task_images[subject][run].shape[-1]\n",
    "            g2.create_dataset('difumodata', data=difumo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95db5af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2248576a",
   "metadata": {},
   "source": [
    "### Average within blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b001a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(output_dir, 'haxby_data_cleaned.h5'), 'a') as hf:\n",
    "\n",
    "    subjects = [int(sub) for sub in layout.get_subjects()]\n",
    "    for subject in subjects:\n",
    "        runs = get_subject_runs(subject, data_dir)\n",
    "        for run in runs:\n",
    "            conditions = [\n",
    "                i.decode('utf-8')\n",
    "                for i in hf[f'sub-{subject}/run-{run}']['conditions'][:]\n",
    "            ]\n",
    "\n",
    "            vt_df = pd.DataFrame(\n",
    "                hf[f'sub-{subject}/run-{run}']['vtmaskdata'][:]\n",
    "            )\n",
    "            condition_mean_df = vt_df.groupby(conditions).mean().sort_index()\n",
    "            conditions_collapsed = condition_mean_df.index.values\n",
    "            hf[f'sub-{subject}/run-{run}'].create_dataset(\n",
    "                'mean_vtmaskdata', data=condition_mean_df\n",
    "            )\n",
    "            hf[f'sub-{subject}/run-{run}'].create_dataset(\n",
    "                'mean_conditions', data=condition_mean_df.index.values\n",
    "            )\n",
    "\n",
    "            # same for whole brain\n",
    "            brain_df = pd.DataFrame(\n",
    "                hf[f'sub-{subject}/run-{run}']['braindata'][:]\n",
    "            )\n",
    "            condition_mean_df = (\n",
    "                brain_df.groupby(conditions).mean().sort_index()\n",
    "            )\n",
    "            # make sure conditions are the same between the two\n",
    "            assert np.all(\n",
    "                condition_mean_df.index.values == conditions_collapsed\n",
    "            )\n",
    "            hf[f'sub-{subject}/run-{run}'].create_dataset(\n",
    "                'mean_braindata', data=condition_mean_df\n",
    "            )\n",
    "\n",
    "            # same for difumo\n",
    "            difumo_df = pd.DataFrame(\n",
    "                hf[f'sub-{subject}/run-{run}']['difumodata'][:]\n",
    "            )\n",
    "            condition_mean_df = (\n",
    "                difumo_df.groupby(conditions).mean().sort_index()\n",
    "            )\n",
    "            # make sure conditions are the same between the two\n",
    "            assert np.all(\n",
    "                condition_mean_df.index.values == conditions_collapsed\n",
    "            )\n",
    "            hf[f'sub-{subject}/run-{run}'].create_dataset(\n",
    "                'mean_difumodata', data=condition_mean_df\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_mean_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b8babe",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "with h5py.File(os.path.join(output_dir, 'haxby_data_cleaned.h5'), 'r') as hf:\n",
    "\n",
    "    # utils.list_all_datasets(hf)\n",
    "    print(hf[f'sub-{subject}/run-{run}']['braindata'].shape)\n",
    "    print(hf[f'sub-{subject}/run-{run}']['vtmaskdata'].shape)\n",
    "    print(hf[f'sub-{subject}/run-{run}']['difumodata'].shape)\n",
    "\n",
    "    print(hf[f'sub-{subject}/run-{run}']['conditions'].shape)\n",
    "    print(hf[f'sub-{subject}/run-{run}']['mean_conditions'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf4002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
